# 100GB database config file (NOTE: make sure you have enough space on disk before running the experiment)

# hardware config
mem_alloc: [10737418240] #cgroup dram allocation
cpu_alloc: [10] #cgroup cpu allocation

# first list all the config flags that need source compilation
code: ["prismdb"]
ssd: ["het"] #"het" for optane+flash setting, "optane" for optane only and "qlc" for flash only
optane_path: ['/users/peiqi714/nvme/prism'] #optane ssd path
flash_path: ['/users/peiqi714/ssd/prism'] #flash ssd path
optane_ratio: [0.1] #optane to flash ratio
pop_cache_size: [0] #clock cache size in terms of keys
pop_cache_thresh: [0.7] #clock cache optane pinning threshold
blockcache_size: [0] #blockcache size for caching objects stored on flash (not used)
num_partitions: [8] #number of partitions
db_size: [100000000] #database size in terms of keys
key_size: [8] #key size in bytes
value_size: [64] #value size in bytes

# below config flags do not need source compilation
num_clients: [8] #number of database clients (NOTE: it should be same as number of partitions in current version)
loop: ["close"]
workload: ["ycsba"] #ycsb workload "ycsba", "ycsbb", "ycsbc", ycsbd", "ycsbe", "ycsbf"
distribution: ["zipfian"] # deprecated
distribution_param: [(0 -1)] #(reads distibution, writes distribution). 0 stands for uniform and -1 stands for both read and write coming from the same distribution. distribution_param [(0.99 -1)] means both reads and writes follow Zipfian 0.99
read_ratio: [0] #reads to writes ratio
workload_operations: [100000000] #number of operations
warmup_ratio: [0.50] #warmup ratio
read_logging: [0] # 0 or 1
migration_logging: [1] # 0 or 1
migration_policy: [2] # 1 is oracle, 2 is random
migration_rand_range_num: [8]
migration_metric: [1]
pop_file: [""]